{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pkse-searcher/fsvm-pois-attack-defense/blob/main/Attack_Project_Progress_11_6_2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VInjfulhjCUR"
      },
      "outputs": [],
      "source": [
        "from sklearn import svm\n",
        "from random import randint, shuffle, uniform\n",
        "from copy import copy,deepcopy\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from math import isclose, fabs\n",
        "\n",
        "from joblib import Memory\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "mem = Memory(\"./mycache\")\n",
        "\n",
        "import pip\n",
        "\n",
        "def install(package):\n",
        "    if hasattr(pip, 'main'):\n",
        "        pip.main(['install', package])\n",
        "    else:\n",
        "        pip._internal.main(['install', package])\n",
        "\n",
        "try:\n",
        "  import secml\n",
        "except:\n",
        "  install('git+https://gitlab.com/secml/secml')\n",
        "  import secml\n",
        "from secml.ml.classifiers import CClassifierSVM\n",
        "from secml.ml.kernels import CKernelRBF\n",
        "from secml.adv.attacks import CAttackPoisoningSVM\n",
        "from secml.data import CDataset\n",
        "from secml.data.splitter import CTrainTestSplit\n",
        "from secml.ml.kernels.c_kernel_linear import CKernelLinear\n",
        "from secml.data.loader import CDLRandomBlobs\n",
        "from secml.array import CArray\n",
        "from sklearn.model_selection import train_test_split\n",
        "# NBVAL_IGNORE_OUTPUT\n",
        "from secml.data.loader import CDataLoaderMNIST, CDataLoaderCIFAR10\n",
        "\n",
        "\n",
        "import gzip\n",
        "import struct\n",
        "from array import array\n",
        "from multiprocessing import Lock\n",
        "import numpy as np\n",
        "\n",
        "from secml.data.loader import CDataLoader\n",
        "from secml.data import CDataset, CDatasetHeader\n",
        "from secml.array import CArray\n",
        "from secml.utils import fm\n",
        "from secml.utils.download_utils import dl_file_gitlab, md5\n",
        "from secml.settings import SECML_DS_DIR\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "  from pyod.models.knn import KNN\n",
        "except:\n",
        "  install('pyod')\n",
        "  from pyod.models.knn import KNN\n",
        "from pyod.models.cblof import CBLOF\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.copod import COPOD\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6Y0q7jmoR1p"
      },
      "outputs": [],
      "source": [
        "def model_change(advNumber, local_machine, w, b):\n",
        "    if local_machine>=advNumber: # if non attacker no model is changed\n",
        "        return w, b\n",
        "    global old_w, old_b\n",
        "    if MODE == 'COLLABORAT' and local_machine != 0:\n",
        "        return old_w, old_b\n",
        "    if ATTACK_TYPE == 'RANDOM':\n",
        "        tw = deepcopy(w)\n",
        "        mx = w.max()\n",
        "        mn = w.min()\n",
        "        for x in range(w.size):\n",
        "            tw[x] = uniform(mn, mx)\n",
        "        old_w, old_b = tw, b\n",
        "        return tw, b\n",
        "\n",
        "\n",
        "\n",
        "    if ATTACK_TYPE == 'AGR_KRUM':\n",
        "        tw = deepcopy(w)\n",
        "        all_updates = []\n",
        "        for adv_local_machine in range(advNumber):\n",
        "            adv_Xlocal = deepcopy(XGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "            adv_ylocal = deepcopy(yGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "\n",
        "            # print(local_machine, y_local)\n",
        "\n",
        "            adv_clfLocals = CClassifierSVM(C=1)\n",
        "            adv_clfLocals.fit(adv_Xlocal, adv_ylocal)\n",
        "\n",
        "            adv_w, adv_b = adv_clfLocals.w.get_data()[0], adv_clfLocals.b.get_data()[0]\n",
        "            adv_m = np.sqrt(adv_w.dot(adv_w))\n",
        "            adv_w = adv_w / adv_m\n",
        "            adv_b /= adv_m\n",
        "            all_updates.append(np.append(adv_w,adv_b))\n",
        "\n",
        "        model_re = np.append(w,b)\n",
        "        n_attackers = advNumber\n",
        "        dev_type = 'std'\n",
        "        deviation = np.std(all_updates, 0)\n",
        "\n",
        "        lamda = 3.0\n",
        "\n",
        "        threshold_diff = 1e-5\n",
        "        lamda_fail = lamda\n",
        "        lamda_succ = 0\n",
        "\n",
        "        while fabs(lamda_succ - lamda) > threshold_diff:\n",
        "            mal_update = (model_re - lamda * deviation)\n",
        "            # print(mal_update)\n",
        "            mal_updates = np.full((n_attackers, mal_update.size), mal_update)\n",
        "            # print(f'{mal_updates[0].shape} and {all_updates[0].shape}')\n",
        "            # print(f'{len(mal_updates)} and {len(all_updates)}')\n",
        "            mal_updates = np.concatenate((mal_updates, all_updates))\n",
        "\n",
        "            hSets =  mal_updates\n",
        "            krum_scores = []\n",
        "            byzantine_client_num = len(hSets) // 5\n",
        "            # print(f'lambda {lambda_} number of adversary {advNumber} and updates {len(all_updates)} and hSets {len(hSets)}')\n",
        "            for i in range(0, len(hSets)):\n",
        "                dists = []\n",
        "                for j in range(0, len(hSets)):\n",
        "                    if i != j:\n",
        "                        temp_vector = np.subtract(hSets[i], hSets[j])\n",
        "                        distance = np.dot(temp_vector,temp_vector)\n",
        "                        dists.append(distance)\n",
        "                #   print(i, \"all_socre\", dists)\n",
        "                dists.sort()  # ascending\n",
        "                score = dists[0 : len(hSets) - byzantine_client_num - 2]\n",
        "                # print(i, \"low_socre\", score)\n",
        "                krum_scores.append(sum(score))\n",
        "                # print(i, krum_scores[-1])\n",
        "            score_index = np.argsort(krum_scores)  # indices; ascending\n",
        "            #   print(krum_scores)\n",
        "            #   print(score_index)\n",
        "            krum_candidate = score_index[0 : len(hSets) - byzantine_client_num - 2]\n",
        "\n",
        "            if np.sum(krum_candidate < n_attackers) == n_attackers:\n",
        "                # print('successful lamda is ', lamda)\n",
        "                lamda_succ = lamda\n",
        "                lamda = lamda + lamda_fail / 2\n",
        "            else:\n",
        "                lamda = lamda - lamda_fail / 2\n",
        "\n",
        "            lamda_fail = lamda_fail / 2\n",
        "\n",
        "        mal_update = (model_re - lamda_succ * deviation)\n",
        "        tw = mal_update[0: len(mal_update) - 1]\n",
        "        b = mal_update[len(mal_update) - 1]\n",
        "        # print(f'The lambda = {lambda_}\\n tw = {tw}\\n b = {b}\\n')\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if ATTACK_TYPE == 'LIE':\n",
        "        tw = deepcopy(w)\n",
        "        num_std = 1.5\n",
        "        users_grads = []\n",
        "        for adv_local_machine in range(advNumber):\n",
        "            adv_Xlocal = deepcopy(XGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "            adv_ylocal = deepcopy(yGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "\n",
        "            # print(local_machine, y_local)\n",
        "\n",
        "            adv_clfLocals = CClassifierSVM(C=1)\n",
        "            adv_clfLocals.fit(adv_Xlocal, adv_ylocal)\n",
        "\n",
        "            adv_w, adv_b = adv_clfLocals.w.get_data()[0], adv_clfLocals.b.get_data()[0]\n",
        "            adv_m = np.sqrt(adv_w.dot(adv_w))\n",
        "            adv_w = adv_w / adv_m\n",
        "            adv_b /= adv_m\n",
        "            users_grads.append(np.append(adv_w,adv_b))\n",
        "\n",
        "        grads_mean = np.mean(users_grads, axis=0)\n",
        "        grads_stdev = np.var(users_grads, axis=0) ** 0.5\n",
        "\n",
        "        grads_mean[:] -= num_std * grads_stdev[:]\n",
        "\n",
        "        tw = grads_mean[0: -1]\n",
        "        b = grads_mean[ -1]\n",
        "        print(f'The grads_mean = {grads_mean.shape}\\n tw = {tw.shape}\\n b = {b}\\n')\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "\n",
        "    if ATTACK_TYPE == 'FANG_KRUM':\n",
        "        tw = deepcopy(w)\n",
        "\n",
        "        agg_updates = np.append(tw,b)\n",
        "        deviation = np.sign(agg_updates)\n",
        "\n",
        "        all_updates = []\n",
        "        for adv_local_machine in range(advNumber):\n",
        "            adv_Xlocal = deepcopy(XGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "            adv_ylocal = deepcopy(yGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "\n",
        "            # print(local_machine, y_local)\n",
        "\n",
        "            adv_clfLocals = CClassifierSVM(C=1)\n",
        "            adv_clfLocals.fit(adv_Xlocal, adv_ylocal)\n",
        "\n",
        "            adv_w, adv_b = adv_clfLocals.w.get_data()[0], adv_clfLocals.b.get_data()[0]\n",
        "            adv_m = np.sqrt(adv_w.dot(adv_w))\n",
        "            adv_w = adv_w / adv_m\n",
        "            adv_b /= adv_m\n",
        "            all_updates.append(np.append(adv_w,adv_b))\n",
        "\n",
        "        # lambda_ = 5\n",
        "        st, fn = 1e-5, 5\n",
        "        while fabs(fn-st) > 1e-5 and st<fn:\n",
        "            lambda_ = (st+fn) / 2\n",
        "            adv_updates = agg_updates - lambda_ * deviation\n",
        "            # print(f'adv_updates {adv_updates}')\n",
        "            hSets = np.vstack([all_updates, adv_updates])\n",
        "\n",
        "            krum_scores = []\n",
        "            byzantine_client_num = 1\n",
        "            # print(f'lambda {lambda_} number of adversary {advNumber} and updates {len(all_updates)} and hSets {len(hSets)}')\n",
        "            for i in range(0, len(hSets)):\n",
        "                dists = []\n",
        "                for j in range(0, len(hSets)):\n",
        "                    if i != j:\n",
        "                        temp_vector = np.subtract(hSets[i], hSets[j])\n",
        "                        distance = np.dot(temp_vector,temp_vector)\n",
        "                        dists.append(distance)\n",
        "                #   print(i, \"all_socre\", dists)\n",
        "                dists.sort()  # ascending\n",
        "                score = dists[0 : len(hSets) - byzantine_client_num - 2]\n",
        "                # print(i, \"low_socre\", score)\n",
        "                krum_scores.append(sum(score))\n",
        "                # print(i, krum_scores[-1])\n",
        "            score_index = np.argsort(krum_scores)  # indices; ascending\n",
        "            #   print(krum_scores)\n",
        "            #   print(score_index)\n",
        "            score_index = score_index[0 : len(hSets) - byzantine_client_num - 2]\n",
        "            if advNumber in score_index:\n",
        "                st = lambda_\n",
        "            else:\n",
        "                fn = lambda_\n",
        "        tw = adv_updates[0: len(adv_updates) - 1]\n",
        "        b = adv_updates[len(adv_updates) - 1]\n",
        "        # print(f'The lambda = {lambda_}\\n tw = {tw}\\n b = {b}\\n')\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "\n",
        "    if ATTACK_TYPE == 'OUR_ATTACK_BND_KRUM':\n",
        "        tw = deepcopy(w)\n",
        "\n",
        "        agg_updates = np.append(tw,b)\n",
        "        deviation = np.sign(agg_updates)\n",
        "\n",
        "        for j in range(w.size):\n",
        "            sum_ = 0\n",
        "            for i in range(len(XGlobal)):\n",
        "                sum_ += (-1 if yGlobal[i] == 0 else 1) * XGlobal[i][j]\n",
        "            print(f'j = {j} deviation {deviation[j]} sum = {sum_} new {1 if sum_ >= 0 else -1}')\n",
        "            agg_updates[j] = -fabs(w[j]) if sum_ >= 0 else fabs(w[j])\n",
        "            deviation[j] = -1 if sum_ >= 0 else 1\n",
        "            # tw[j] = -1000 if sum_ >= 0 else 1000\n",
        "            # print(j, w[j], tw[j], sum_)\n",
        "\n",
        "\n",
        "        all_updates = []\n",
        "        for adv_local_machine in range(advNumber):\n",
        "            adv_Xlocal = deepcopy(XGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "            adv_ylocal = deepcopy(yGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "\n",
        "            # print(local_machine, y_local)\n",
        "\n",
        "            adv_clfLocals = CClassifierSVM(C=1)\n",
        "            adv_clfLocals.fit(adv_Xlocal, adv_ylocal)\n",
        "\n",
        "            adv_w, adv_b = adv_clfLocals.w.get_data()[0], adv_clfLocals.b.get_data()[0]\n",
        "            adv_m = np.sqrt(adv_w.dot(adv_w))\n",
        "            adv_w = adv_w / adv_m\n",
        "            adv_b /= adv_m\n",
        "            all_updates.append(np.append(adv_w,adv_b))\n",
        "\n",
        "        # lambda_ = 5\n",
        "        st, fn = 1e-5, 20\n",
        "        while fabs(fn-st) > 1e-5 and st<fn:\n",
        "            lambda_ = (st+fn) / 2\n",
        "            adv_updates = agg_updates - lambda_ * deviation\n",
        "            # print(f'adv_updates {adv_updates}')\n",
        "            hSets = np.vstack([all_updates, adv_updates])\n",
        "\n",
        "            krum_scores = []\n",
        "            byzantine_client_num = 1\n",
        "            print(f'lambda {lambda_} number of adversary {advNumber} and updates {len(all_updates)} and hSets {len(hSets)}')\n",
        "            for i in range(0, len(hSets)):\n",
        "                dists = []\n",
        "                for j in range(0, len(hSets)):\n",
        "                    if i != j:\n",
        "                        temp_vector = np.subtract(hSets[i], hSets[j])\n",
        "                        distance = np.dot(temp_vector,temp_vector)\n",
        "                        dists.append(distance)\n",
        "                #   print(i, \"all_socre\", dists)\n",
        "                dists.sort()  # ascending\n",
        "                score = dists[0 : len(hSets) - byzantine_client_num - 2]\n",
        "                # print(i, \"low_socre\", score)\n",
        "                krum_scores.append(sum(score))\n",
        "                # print(i, krum_scores[-1])\n",
        "            score_index = np.argsort(krum_scores)  # indices; ascending\n",
        "            #   print(krum_scores)\n",
        "            #   print(score_index)\n",
        "            score_index = score_index[0 : len(hSets) - byzantine_client_num - 2]\n",
        "            if advNumber == score_index[0]:\n",
        "                st = lambda_\n",
        "            else:\n",
        "                fn = lambda_\n",
        "        tw = adv_updates[0: len(adv_updates) - 1]\n",
        "        b = adv_updates[len(adv_updates) - 1]\n",
        "        print(f'The lambda = {lambda_}\\n tw = {tw}\\n b = {b}\\n')\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "\n",
        "    if ATTACK_TYPE == 'OUR_ATTACK':\n",
        "        tw = deepcopy(w)\n",
        "        mx = w.max()\n",
        "        mn = w.min()\n",
        "        # print(mn, mx)\n",
        "        for j in range(w.size):\n",
        "            sum_ = 0\n",
        "            for i in range(len(XGlobal)):\n",
        "                sum_ += (-1 if yGlobal[i] == 0 else 1) * XGlobal[i][j]\n",
        "                # print('\\t', i, j, -1 if testy[i] == 0 else 1, testX[i][j], sum_)\n",
        "            # tw[j] = mn if sum_ >= 0 else mx\n",
        "            tw[j] = -fabs(w[j]) if sum_ >= 0 else fabs(w[j])\n",
        "            # tw[j] = -1000 if sum_ >= 0 else 1000\n",
        "            # print(j, w[j], tw[j], sum_)\n",
        "        m = np.sqrt(tw.dot(tw))\n",
        "        # print(m)\n",
        "        # tw = tw / m\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "\n",
        "    if ATTACK_TYPE == 'OUR_ATTACK_GD':\n",
        "        h=1e-5\n",
        "        tw = deepcopy(w)\n",
        "        def get_error(tw, debug = False):\n",
        "            w_g = (advNumber*tw + (num_local_machine-advNumber)*w)/num_local_machine\n",
        "            # temp_vector = np.subtract(tw, w)\n",
        "            # distance = np.dot(temp_vector,temp_vector)\n",
        "            error_sum=0\n",
        "            for i in range(len(testX)):\n",
        "                res = 1+(-1 if testy[i] == 0 else 1) * (np.dot(testX[i],w_g)+b)\n",
        "                # print(f\"res {res} y {yGlobal[i]} and det {np.dot(testX[i],w_g)+b}\")\n",
        "                error_sum += max(0, res)\n",
        "            # if debug: print(f'iter {_} i {i} distance {distance} error_sum {error_sum}')\n",
        "            return error_sum # + 500*distance\n",
        "        iter=40\n",
        "        prev_acc = 0\n",
        "        mx = w.max()\n",
        "        mn = w.min()\n",
        "        for _ in range(iter):\n",
        "            cur_acc = get_error(tw, True)\n",
        "            if(cur_acc < 1e-3 or fabs(prev_acc-cur_acc)/cur_acc < 1e-5):\n",
        "                break\n",
        "            cnt = 0\n",
        "            for i in range(len(testX)):\n",
        "                det = np.dot(np.append(testX[i], 1), np.append(tw,b))\n",
        "                if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1): cnt += 1\n",
        "            # print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after iter {_} and error {cur_acc} and ratio with previous {fabs(prev_acc-cur_acc)/cur_acc}')\n",
        "            prev_acc = cur_acc\n",
        "\n",
        "\n",
        "            for j in range(w.size):\n",
        "                tw[j]=tw[j]+h\n",
        "                err_add = get_error(tw)\n",
        "\n",
        "                tw[j]=tw[j]-2*h\n",
        "                err_sub = get_error(tw)\n",
        "\n",
        "                tw[j]=tw[j]+h\n",
        "                gradient = (err_add-err_sub)/(2*h)\n",
        "                # print(err_add,err_sub, gradient)\n",
        "\n",
        "                tw[j]=tw[j]-0.03*gradient\n",
        "                # if tw[j] > 2*mx: tw[j] = 2*mx\n",
        "                # if tw[j] < 2*mn: tw[j] = 2*mn\n",
        "\n",
        "        # agg_updates = np.append(tw,b)\n",
        "        # orig_updates = np.append(w,b)\n",
        "\n",
        "        # all_updates = []\n",
        "        # for adv_local_machine in range(advNumber):\n",
        "        #     adv_Xlocal = deepcopy(XGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "        #     adv_ylocal = deepcopy(yGlobal[adv_local_machine * slc : (adv_local_machine + 1) * slc])\n",
        "\n",
        "        #     # print(local_machine, y_local)\n",
        "\n",
        "        #     adv_clfLocals = CClassifierSVM(C=1)\n",
        "        #     adv_clfLocals.fit(adv_Xlocal, adv_ylocal)\n",
        "\n",
        "        #     adv_w, adv_b = adv_clfLocals.w.get_data()[0], adv_clfLocals.b.get_data()[0]\n",
        "        #     adv_m = np.sqrt(adv_w.dot(adv_w))\n",
        "        #     adv_w = adv_w / adv_m\n",
        "        #     adv_b /= adv_m\n",
        "        #     all_updates.append(np.append(adv_w,adv_b))\n",
        "\n",
        "        # iter = 40\n",
        "        # for _ in range(iter):\n",
        "        #     hSets = np.vstack([all_updates, agg_updates])\n",
        "\n",
        "        #     krum_scores = []\n",
        "        #     byzantine_client_num = 1\n",
        "        #     # print(f'lambda {lambda_} number of adversary {advNumber} and updates {len(all_updates)} and hSets {len(hSets)}')\n",
        "        #     for i in range(0, len(hSets)):\n",
        "        #         dists = []\n",
        "        #         for j in range(0, len(hSets)):\n",
        "        #             if i != j:\n",
        "        #                 temp_vector = np.subtract(hSets[i], hSets[j])\n",
        "        #                 distance = np.dot(temp_vector,temp_vector)\n",
        "        #                 dists.append(distance)\n",
        "        #         #   print(i, \"all_socre\", dists)\n",
        "        #         dists.sort()  # ascending\n",
        "        #         score = dists[0 : len(hSets) - byzantine_client_num - 2]\n",
        "        #         # print(i, \"low_socre\", score)\n",
        "        #         krum_scores.append(sum(score))\n",
        "        #         # print(i, krum_scores[-1])\n",
        "        #     score_index = np.argsort(krum_scores)  # indices; ascending\n",
        "        #     #   print(krum_scores)\n",
        "        #     #   print(score_index)\n",
        "        #     score_index = score_index[0 : len(hSets) - byzantine_client_num - 2]\n",
        "        #     if advNumber == score_index[0]:\n",
        "        #         break\n",
        "        #     agg_updates = (agg_updates+orig_updates) / 2\n",
        "        # tw = agg_updates[0: len(agg_updates) - 1]\n",
        "        # b = agg_updates[len(agg_updates) - 1]\n",
        "        # print(f'The iter = {_} b = {b}\\n')\n",
        "\n",
        "        old_w, old_b = tw,b\n",
        "        return tw, b\n",
        "    old_w, old_b = w, b\n",
        "    return w, b\n",
        "\n",
        "\n",
        "\n",
        "def load_local_data(advNumber, local_machine):\n",
        "    global old_x_local, old_y_local\n",
        "    # return XGlobal, yGlobal\n",
        "\n",
        "    if local_machine>=advNumber: # if non attacker no dataset is changed\n",
        "        Xlocal = deepcopy(XGlobal[local_machine * slc : (local_machine + 1) * slc])\n",
        "        ylocal = deepcopy(yGlobal[local_machine * slc : (local_machine + 1) * slc])\n",
        "        # print(\"labels of \", local_machine, ylocal)\n",
        "        return Xlocal, ylocal\n",
        "\n",
        "\n",
        "    if MODE==\"COLLABORAT\":\n",
        "        if local_machine !=0:\n",
        "            return old_x_local, old_y_local\n",
        "        Xlocal = deepcopy(XGlobal[0 : advNumber * slc])\n",
        "        ylocal = deepcopy(yGlobal[0 : advNumber * slc])\n",
        "    else:\n",
        "        Xlocal = deepcopy(XGlobal[local_machine * slc : (local_machine + 1) * slc])\n",
        "        ylocal = deepcopy(yGlobal[local_machine * slc : (local_machine + 1) * slc])\n",
        "\n",
        "\n",
        "\n",
        "    if ATTACK_TYPE == 'LABEL_FLIP':\n",
        "        for j in range(len(ylocal)):\n",
        "            ylocal[j] ^= 1\n",
        "        old_x_local, old_y_local = Xlocal, ylocal\n",
        "        return Xlocal, ylocal\n",
        "\n",
        "    if ATTACK_TYPE == 'OPTIMAL':\n",
        "        n_tr = int(len(ylocal)*0.4)  # Number of training set samples\n",
        "        n_val = int(len(ylocal)*0.5)  # Number of validation set samples\n",
        "        n_ts = len(ylocal) - n_tr - n_val  # Number of test set samples\n",
        "\n",
        "        # Split in training, validation and test\n",
        "        dataset = CDataset(Xlocal, ylocal)\n",
        "        random_state = 999\n",
        "        splitter = CTrainTestSplit(train_size=n_tr + n_val, test_size=n_ts, random_state=random_state)\n",
        "        tr_val, ts = splitter.split(dataset)\n",
        "        splitter = CTrainTestSplit(train_size=n_tr, test_size=n_val, random_state=random_state)\n",
        "        tr, val = splitter.split(dataset)\n",
        "        tr = tr.append(ts)\n",
        "\n",
        "        clf = CClassifierSVM(kernel=CKernelLinear(), C=1)\n",
        "\n",
        "        # We can now fit the classifier\n",
        "        clf.fit(tr.X, tr.Y)\n",
        "\n",
        "        # Should be chosen depending on the optimization problem\n",
        "        lb, ub = 0., 1.  # Bounds of the attack space. Can be set to `None` for unbounded\n",
        "\n",
        "        # Should be chosen depending on the optimization problem\n",
        "        solver_params = {\n",
        "            'eta': 0.25,\n",
        "            'eta_min': 2.0,\n",
        "            'eta_max': None,\n",
        "            'max_iter': 200,\n",
        "            'eps': 1e-8\n",
        "        }\n",
        "\n",
        "        pois_attack = CAttackPoisoningSVM(classifier=clf,\n",
        "                                      training_data=tr,\n",
        "                                      val=val,\n",
        "                                      lb=lb, ub=ub,\n",
        "                                      solver_params=solver_params,\n",
        "                                      random_seed=random_state)\n",
        "\n",
        "        n_poisoning_points = 20  # Number of poisoning points to generate\n",
        "        pois_attack.n_points = n_poisoning_points\n",
        "\n",
        "        #Run the poisoning attack\n",
        "        # print(\"Attack started...\")\n",
        "        pois_y_pred, pois_scores, pois_ds, f_opt = pois_attack.run(ts.X, ts.Y)\n",
        "        # print(\"Attack complete!\")\n",
        "        # tr = tr.append(pois_ds) #.append(val)\n",
        "        Xlocal, ylocal = pois_ds.X.get_data(), pois_ds.Y.get_data()\n",
        "        old_x_local, old_y_local = Xlocal, ylocal\n",
        "        # print(Xlocal)\n",
        "        # print(ylocal)\n",
        "        return Xlocal, ylocal\n",
        "    #if ATTACK_TYPE == 'RANDOM' or ATTACK_TYPE == 'OUR_ATTACK' or ATTACK_TYPE == 'OUR_ATTACK_GD':\n",
        "    # if model attacker then no dataset is changed\n",
        "    old_x_local, old_y_local = Xlocal, ylocal\n",
        "    return Xlocal, ylocal\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def dataLoad(p = 50):\n",
        "    global dataset_type, XGlobal, yGlobal, testX, testy, slc\n",
        "    if dataset_type == 'MNIST':\n",
        "        # MNIST dataset will be downloaded and cached if needed\n",
        "        loader = CDataLoaderMNIST()\n",
        "\n",
        "        slc = 100\n",
        "        size_all = 784\n",
        "\n",
        "        # total MNIST data with 5 and 9 is 11370\n",
        "        n_samples = slc * num_local_machine  # Number of samples\n",
        "        digits = (9, 8)\n",
        "\n",
        "        dataset = loader.load('training', digits=digits)\n",
        "        # Normalize the features in `[0, 1]`\n",
        "        dataset.X /= 255\n",
        "        XGlobal, yGlobal = dataset.X.get_data(), dataset.Y.get_data()\n",
        "\n",
        "        test_dataset = loader.load('testing', digits=digits, num_samples=1000)\n",
        "        test_dataset.X /= 255\n",
        "        testX, testy = test_dataset.X.get_data(), test_dataset.Y.get_data()\n",
        "\n",
        "\n",
        "    if dataset_type == 'IJCNN1':\n",
        "\n",
        "        XGlobal, yGlobal = load_svmlight_file('/content/sample_data/ijcnn1.tr.bz2')\n",
        "        XGlobal = XGlobal.toarray()\n",
        "        yGlobal = [0 if y < 0 else 1 for y in yGlobal]\n",
        "\n",
        "        testX, testy = load_svmlight_file('/content/sample_data/ijcnn1.t.bz2')\n",
        "        testX = testX.toarray()\n",
        "        testy = [0 if y < 0 else 1 for y in testy]\n",
        "\n",
        "        slc = 300\n",
        "\n",
        "    if dataset_type == 'FASHION_MNIST':\n",
        "        # MNIST dataset will be downloaded and cached if needed\n",
        "        train_df = pd.read_csv('/content/sample_data/fashion-mnist_train.csv')\n",
        "        test_df = pd.read_csv('/content/sample_data/fashion-mnist_test.csv')\n",
        "        print('The shape of training dataset : ', train_df.shape)\n",
        "        print('The shape of testing dataset : ', test_df.shape)\n",
        "\n",
        "        train = np.array(train_df, dtype = 'float32')\n",
        "        test = np.array(test_df, dtype = 'float32')\n",
        "\n",
        "\n",
        "        trainX = train[:,1:]/255\n",
        "\n",
        "        trainY = train[:,0]\n",
        "\n",
        "        dataX = test[:,1:]/255\n",
        "\n",
        "        dataY=test[:,0]\n",
        "\n",
        "        def gen_data(X, Y):\n",
        "            retX, retY = [], []\n",
        "            for i in range(len(Y)):\n",
        "                # print(i, trainY[i])\n",
        "                lbl = int(Y[i])\n",
        "                if lbl == 0 or lbl == 6:\n",
        "                    retX.append(X[i])\n",
        "                    retY.append(0 if lbl == 0 else 1)\n",
        "            # class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "            #    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "            # plt.figure(figsize=(17, 17))\n",
        "            # for i in range(25):\n",
        "            #     plt.subplot(5, 5, i + 1)\n",
        "            #     plt.grid(False)\n",
        "            #     plt.imshow(retX[i].reshape((28,28)))\n",
        "            #     plt.colorbar()\n",
        "            #     label_index = int(retY[i])\n",
        "            #     plt.title(class_names[label_index])\n",
        "            # plt.show()\n",
        "            return retX, retY\n",
        "\n",
        "        XGlobal, yGlobal = gen_data(trainX, trainY)\n",
        "        unique, counts = np.unique(yGlobal, return_counts=True)\n",
        "        print(f\"Global count {dict(zip(unique, counts))}\")\n",
        "        testX, testy = gen_data(dataX, dataY)\n",
        "\n",
        "        print(len(trainY), len(dataY))\n",
        "\n",
        "        unique, counts = np.unique(testy, return_counts=True)\n",
        "        print(f\"Test count {dict(zip(unique, counts))}\")\n",
        "        print(len(yGlobal), testy)\n",
        "\n",
        "        slc = 100\n",
        "        size_all = 784\n",
        "        # class_names = ['T_shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "        #        'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "        # plt.figure(figsize=(17, 17))\n",
        "\n",
        "        # for i in range(25):\n",
        "        #     plt.subplot(5, 5, i + 1)\n",
        "        #     plt.grid(False)\n",
        "        #     plt.imshow(testX[i].reshape((28,28)))\n",
        "        #     plt.colorbar()\n",
        "        #     label_index = int(testy[i])\n",
        "        #     plt.title(class_names[label_index])\n",
        "        # plt.show()\n",
        "\n",
        "    elif dataset_type == 'CIFAR10':\n",
        "        # CIFAR10 dataset will be downloaded and cached if needed\n",
        "        loader = CDataLoaderCIFAR10()\n",
        "\n",
        "        def rgb_2_gray(arr):\n",
        "            return [0.2989 * arr[i] + 0.5870 * arr[i+1024] + 0.1140 * arr[i+2048] for i in range(1024)]\n",
        "\n",
        "        size_all = 1024\n",
        "        slc = 100\n",
        "\n",
        "        # total MNIST data with 5 and 9 is 11370\n",
        "        n_samples = slc * num_local_machine  # Number of samples\n",
        "\n",
        "        dataset, test_dataset = loader.load()\n",
        "        # Normalize the features in `[0, 1]`\n",
        "        dataset.X /= 255\n",
        "\n",
        "        XGlobal, yGlobal = [], []\n",
        "        trainX = dataset.X.get_data()\n",
        "        trainY = dataset.Y.get_data()\n",
        "\n",
        "        for i in range(len(trainY)):\n",
        "            if trainY[i] < 2:\n",
        "                XGlobal.append(rgb_2_gray(trainX[i]))\n",
        "                yGlobal.append(trainY[i])\n",
        "\n",
        "        unique, counts = np.unique(yGlobal, return_counts=True)\n",
        "        print(f\"Global count {dict(zip(unique, counts))}\")\n",
        "        testX, testy = [], []\n",
        "        test_dataset.X /= 255\n",
        "        dataX = test_dataset.X.get_data()\n",
        "        dataY = test_dataset.Y.get_data()\n",
        "\n",
        "        print(len(trainY), len(dataY))\n",
        "\n",
        "        for i in range(len(dataY)):\n",
        "            if dataY[i] < 2:\n",
        "                testX.append(rgb_2_gray(dataX[i]))\n",
        "                testy.append(dataY[i])\n",
        "\n",
        "        unique, counts = np.unique(testy, return_counts=True)\n",
        "        print(f\"Test count {dict(zip(unique, counts))}\")\n",
        "        print(len(yGlobal), len(testy))\n",
        "\n",
        "    if p == -1:\n",
        "        data = [[], []]\n",
        "        sz = len(yGlobal)\n",
        "        for i in range(sz):\n",
        "            data[yGlobal[i]].append(XGlobal[i])\n",
        "        XGlobal, yGlobal = [], []\n",
        "        print(f\"Changing data, p={p} and slc = {slc}\")\n",
        "        for edge_device in range(num_local_machine):\n",
        "            label = 0\n",
        "            data_iid = edge_device + (0 if edge_device >= (num_local_machine//2) else 1)\n",
        "            print(f\"edge_device {edge_device}, 0: {len(data[0])}, 1: {len(data[1])}, data_iid {data_iid}\")\n",
        "            for _ in range(data_iid):\n",
        "                XGlobal.append(data[label].pop())\n",
        "                yGlobal.append(label)\n",
        "\n",
        "            anti_label = 1\n",
        "            for _ in range(slc - data_iid):\n",
        "                XGlobal.append(data[anti_label].pop())\n",
        "                yGlobal.append(anti_label)\n",
        "    elif p != 50:\n",
        "        data = [[], []]\n",
        "        sz = len(yGlobal)\n",
        "        for i in range(sz):\n",
        "            data[yGlobal[i]].append(XGlobal[i])\n",
        "        XGlobal, yGlobal = [], []\n",
        "        data_iid = int((slc * p) / 100 + 0.5)\n",
        "        print(f\"Changing data, p={p} and data_iid = {data_iid} and slc = {slc}\")\n",
        "        for edge_device in range(num_local_machine):\n",
        "            label = edge_device%2\n",
        "            for _ in range(data_iid):\n",
        "                XGlobal.append(data[label].pop())\n",
        "                yGlobal.append(label)\n",
        "\n",
        "            anti_label = ( edge_device+1 ) % 2\n",
        "            for _ in range(slc - data_iid):\n",
        "                XGlobal.append(data[anti_label].pop())\n",
        "                yGlobal.append(anti_label)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def outlier_detection(hSets, advNumber, numberMachine):\n",
        "    # detection using KNN\n",
        "\n",
        "    colors = []\n",
        "    for _ in range(advNumber):\n",
        "        colors.append('r')\n",
        "\n",
        "    for _ in range(numberMachine-advNumber):\n",
        "        colors.append('b')\n",
        "\n",
        "    print(f'kNN based out detection')\n",
        "    outlier_clf = KNN(contamination=0.2)\n",
        "    outlier_clf.fit(hSets)\n",
        "\n",
        "    y_train_pred = outlier_clf.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "    y_train_scores = outlier_clf.decision_scores_  # raw outlier scores\n",
        "    # for i in range(len(hSets)):\n",
        "    #     print(\"Machine {}, prediction {} outlier score {}\".format(i, y_train_pred[i], y_train_scores[i]))\n",
        "    print(f\"For kNN with adversary {advNumber}, adversarial : min: {np.amin(y_train_scores[0:advNumber])} max: {np.amax(y_train_scores[0:advNumber])} avg: {np.mean(y_train_scores[0:advNumber])}\")\n",
        "    print(f\"For kNN with adversary {advNumber}, non adversarial : min: {np.amin(y_train_scores[advNumber:])} max: {np.amax(y_train_scores[advNumber:])} avg: {np.mean(y_train_scores[advNumber:])}\")\n",
        "    # fig = plt.figure()\n",
        "    # ax = fig.add_axes([0,0,1,1])\n",
        "    # ax.bar(numberMachine,y_train_scores,color=colors)\n",
        "    # ax.set_xlabel('Local Machine')\n",
        "    # ax.set_ylabel('Outlier Score')\n",
        "    # plt.xlabel('Local Machine', fontsize=20)\n",
        "    # plt.ylabel('Outlier Score', fontsize=20)\n",
        "    # plt.xticks(fontsize=16)\n",
        "    # plt.yticks(fontsize=16)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    # detection using k means clustering\n",
        "\n",
        "    # print('k means clustering based out detection')\n",
        "    # outlier_clf_kmeans = CBLOF(beta=len(hSets))\n",
        "    # outlier_clf_kmeans.fit(hSets)\n",
        "    # y_train_pred = outlier_clf_kmeans.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "    # y_train_scores = outlier_clf_kmeans.decision_scores_  # raw outlier scores\n",
        "    # for i in range(len(hSets)):\n",
        "    #         print(\"Machine {}, prediction {} outlier score {}\".format(i, y_train_pred[i], y_train_scores[i]))\n",
        "    # fig = plt.figure()\n",
        "    # ax = fig.add_axes([0,0,1,1])\n",
        "    # ax.bar(numberMachine,y_train_scores,color=colors)\n",
        "    # ax.set_xlabel('Local Machine')\n",
        "    # ax.set_ylabel('Outlier Score')\n",
        "    # plt.xlabel('Local Machine', fontsize=20)\n",
        "    # plt.ylabel('Outlier Score', fontsize=20)\n",
        "    # plt.xticks(fontsize=16)\n",
        "    # plt.yticks(fontsize=16)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    # detection using Histogram- based outlier detection\n",
        "\n",
        "    print('Histogram based out detection')\n",
        "    outlier_clf_hbos = HBOS(n_bins=3)\n",
        "    outlier_clf_hbos.fit(hSets)\n",
        "    y_train_pred = outlier_clf_hbos.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "    y_train_scores = outlier_clf_hbos.decision_scores_  # raw outlier scores\n",
        "    # for i in range(len(hSets)):\n",
        "    #         print(\"Machine {}, prediction {} outlier score {}\".format(i, y_train_pred[i], y_train_scores[i]))\n",
        "    print(f\"For Histogram with adversary {advNumber}, adversarial : min: {np.amin(y_train_scores[0:advNumber])} max: {np.amax(y_train_scores[0:advNumber])} avg: {np.mean(y_train_scores[0:advNumber])}\")\n",
        "    print(f\"For Histogram with adversary {advNumber}, non adversarial : min: {np.amin(y_train_scores[advNumber:])} max: {np.amax(y_train_scores[advNumber:])} avg: {np.mean(y_train_scores[advNumber:])}\")\n",
        "    # fig = plt.figure()\n",
        "    # ax = fig.add_axes([0,0,1,1])\n",
        "    # ax.bar(numberMachine,y_train_scores,color=colors)\n",
        "    # ax.set_xlabel('Local Machine')\n",
        "    # ax.set_ylabel('Outlier Score')\n",
        "    # plt.xlabel('Local Machine', fontsize=20)\n",
        "    # plt.ylabel('Outlier Score', fontsize=20)\n",
        "    # plt.xticks(fontsize=16)\n",
        "    # plt.yticks(fontsize=16)\n",
        "    # plt.show()\n",
        "\n",
        "\n",
        "    # detection using Copula Based Outlier Detector\n",
        "\n",
        "    print('Copula Based Outlier Detector')\n",
        "    outlier_clf_copod = COPOD()\n",
        "    outlier_clf_copod.fit(hSets)\n",
        "    y_train_pred = outlier_clf_copod.labels_  # binary labels (0: inliers, 1: outliers)\n",
        "    y_train_scores = outlier_clf_copod.decision_scores_  # raw outlier scores\n",
        "    # for i in range(len(hSets)):\n",
        "    #         print(\"Machine {}, prediction {} outlier score {}\".format(i, y_train_pred[i], y_train_scores[i]))\n",
        "    print(f\"For Copula with adversary {advNumber}, adversarial : min: {np.amin(y_train_scores[0:advNumber])} max: {np.amax(y_train_scores[0:advNumber])} avg: {np.mean(y_train_scores[0:advNumber])}\")\n",
        "    print(f\"For Copula with adversary {advNumber}, non adversarial : min: {np.amin(y_train_scores[advNumber:])} max: {np.amax(y_train_scores[advNumber:])} avg: {np.mean(y_train_scores[advNumber:])}\")\n",
        "    # fig = plt.figure()\n",
        "    # ax = fig.add_axes([0,0,1,1])\n",
        "    # ax.bar(numberMachine,y_train_scores,color=colors)\n",
        "    # ax.set_xlabel('Local Machine')\n",
        "    # ax.set_ylabel('Outlier Score')\n",
        "    # plt.xlabel('Local Machine', fontsize=20)\n",
        "    # plt.ylabel('Outlier Score', fontsize=20)\n",
        "    # plt.xticks(fontsize=16)\n",
        "    # plt.yticks(fontsize=16)\n",
        "    # plt.show()\n"
      ],
      "metadata": {
        "id": "ScqckU7bWdaw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSlJMgwleX-d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cb0213a-9327-4faf-d172-f0ca7d531843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "CIFAR10 LABEL_FLIP INDIV 100 50\n",
            "Global count {0: 5000, 1: 5000}\n",
            "50000 10000\n",
            "Test count {0: 1000, 1: 1000}\n",
            "10000 2000\n",
            "kNN based out detection\n",
            "For kNN with adversary 30, adversarial : min: 1.3065728925728082 max: 1.391500524514079 avg: 1.3428413295486408\n",
            "For kNN with adversary 30, non adversarial : min: 1.2520679245513524 max: 1.3719337301788113 avg: 1.3210115750051385\n",
            "Histogram based out detection\n",
            "For Histogram with adversary 30, adversarial : min: -3055.860482026873 max: -2967.5147036330363 avg: -3006.9136083566777\n",
            "For Histogram with adversary 30, non adversarial : min: -3118.2636929027976 max: -2995.9056230239157 avg: -3061.2452043460107\n",
            "Copula Based Outlier Detector\n",
            "For Copula with adversary 30, adversarial : min: 1375.5742147342676 max: 1452.049099412915 avg: 1414.5808466856927\n",
            "For Copula with adversary 30, non adversarial : min: 1250.7272340855125 max: 1363.6201303592156 avg: 1299.8053937916418\n",
            "Time 2023-08-11 15:14:07.611447: Accuracy is 1505/2000 = 0.7525 with 30 attacker after average\n",
            "Time 2023-08-11 15:14:07.709426: Accuracy is 645/2000 = 0.3225 with 30 attacker poisonus hyperplane\n",
            "Time 2023-08-11 15:14:07.806919: Accuracy is 1340/2000 = 0.67 with 30 attacker good hyperplane\n",
            "Time 2023-08-11 15:14:08.394519: Accuracy is 1505/2000 = 0.7525 with 30 attacker after clustering\n",
            "Time 2023-08-11 15:14:17.095564: Accuracy is 1505/2000 = 0.7525 with 30 attacker after convergence\n",
            "Time 2023-08-11 15:14:17.211933: Accuracy is 1437/2000 = 0.7185 with 30 attacker after krum\n",
            "Time 2023-08-11 15:14:17.310917: Accuracy is 1507/2000 = 0.7535 with 30 attacker after multi-krum\n",
            "Time 2023-08-11 15:14:17.453617: Accuracy is 1530/2000 = 0.765 with 30 attacker after trimmed mean\n",
            "\n",
            "CIFAR10 OPTIMAL INDIV 100 50\n",
            "Global count {0: 5000, 1: 5000}\n",
            "50000 10000\n",
            "Test count {0: 1000, 1: 1000}\n",
            "10000 2000\n",
            "kNN based out detection\n",
            "For kNN with adversary 30, adversarial : min: 1.2886736788927395 max: 3.2222307610331082 avg: 1.5964839485325013\n",
            "For kNN with adversary 30, non adversarial : min: 1.2520679245513524 max: 1.3719337301788113 avg: 1.3210334987941506\n",
            "Histogram based out detection\n",
            "For Histogram with adversary 30, adversarial : min: -3069.8321051178045 max: -2938.921130607607 avg: -3014.685320031054\n",
            "For Histogram with adversary 30, non adversarial : min: -3126.5576506134653 max: -3010.1679203733174 avg: -3066.573509229283\n",
            "Copula Based Outlier Detector\n",
            "For Copula with adversary 30, adversarial : min: 1329.905794653719 max: 1474.171161920907 avg: 1393.7474192558695\n",
            "For Copula with adversary 30, non adversarial : min: 1231.6550759505726 max: 1382.558215358195 avg: 1308.7340055472803\n",
            "Time 2023-08-11 15:22:22.304232: Accuracy is 1255/2000 = 0.6275 with 30 attacker after average\n",
            "Time 2023-08-11 15:22:22.416725: Accuracy is 692/2000 = 0.346 with 30 attacker poisonus hyperplane\n",
            "Time 2023-08-11 15:22:22.536738: Accuracy is 1340/2000 = 0.67 with 30 attacker good hyperplane\n",
            "Time 2023-08-11 15:22:23.012885: Accuracy is 1255/2000 = 0.6275 with 30 attacker after clustering\n",
            "Time 2023-08-11 15:22:31.973676: Accuracy is 1255/2000 = 0.6275 with 30 attacker after convergence\n",
            "Time 2023-08-11 15:22:32.093768: Accuracy is 1395/2000 = 0.6975 with 30 attacker after krum\n",
            "Time 2023-08-11 15:22:32.192457: Accuracy is 1538/2000 = 0.769 with 30 attacker after multi-krum\n",
            "Time 2023-08-11 15:22:32.332448: Accuracy is 1003/2000 = 0.5015 with 30 attacker after trimmed mean\n",
            "\n",
            "FASHION_MNIST LABEL_FLIP INDIV 100 50\n",
            "The shape of training dataset :  (60000, 785)\n",
            "The shape of testing dataset :  (10000, 785)\n",
            "Global count {0: 6000, 1: 6000}\n",
            "60000 10000\n",
            "Test count {0: 1000, 1: 1000}\n",
            "12000 [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "kNN based out detection\n",
            "For kNN with adversary 30, adversarial : min: 1.2320073020569406 max: 1.3468587216490495 avg: 1.2971888074379858\n",
            "For kNN with adversary 30, non adversarial : min: 1.1991753445217297 max: 1.3643146618739914 avg: 1.270382050838736\n",
            "Histogram based out detection\n",
            "For Histogram with adversary 30, adversarial : min: -2602.3317286336546 max: -2347.564359736957 avg: -2491.6947356801156\n",
            "For Histogram with adversary 30, non adversarial : min: -2634.800320156145 max: -2414.5576496950825 avg: -2544.1892881562612\n",
            "Copula Based Outlier Detector\n",
            "For Copula with adversary 30, adversarial : min: 946.6388992357391 max: 1169.440430502846 avg: 1057.4796117429364\n",
            "For Copula with adversary 30, non adversarial : min: 871.4982293091773 max: 1079.3868476695056 avg: 972.4713032934072\n",
            "Time 2023-08-11 15:22:34.885469: Accuracy is 1680/2000 = 0.84 with 30 attacker after average\n",
            "Time 2023-08-11 15:22:34.897691: Accuracy is 421/2000 = 0.2105 with 30 attacker poisonus hyperplane\n",
            "Time 2023-08-11 15:22:34.909541: Accuracy is 1576/2000 = 0.788 with 30 attacker good hyperplane\n",
            "Time 2023-08-11 15:22:35.270313: Accuracy is 1680/2000 = 0.84 with 30 attacker after clustering\n",
            "Time 2023-08-11 15:22:44.651787: Accuracy is 1680/2000 = 0.84 with 30 attacker after convergence\n",
            "Time 2023-08-11 15:22:44.698780: Accuracy is 1618/2000 = 0.809 with 30 attacker after krum\n",
            "Time 2023-08-11 15:22:44.710427: Accuracy is 1672/2000 = 0.836 with 30 attacker after multi-krum\n",
            "Time 2023-08-11 15:22:44.752418: Accuracy is 1676/2000 = 0.838 with 30 attacker after trimmed mean\n",
            "\n",
            "FASHION_MNIST OPTIMAL INDIV 100 50\n",
            "The shape of training dataset :  (60000, 785)\n",
            "The shape of testing dataset :  (10000, 785)\n",
            "Global count {0: 6000, 1: 6000}\n",
            "60000 10000\n",
            "Test count {0: 1000, 1: 1000}\n",
            "12000 [0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "kNN based out detection\n",
            "For kNN with adversary 30, adversarial : min: 1.190427424131199 max: 2.733082114678588 avg: 1.3910064119765095\n",
            "For kNN with adversary 30, non adversarial : min: 1.1991753445217297 max: 1.3643146618739914 avg: 1.270382050838736\n",
            "Histogram based out detection\n",
            "For Histogram with adversary 30, adversarial : min: -2614.4406217301794 max: -2384.1253999840224 avg: -2528.348740538656\n",
            "For Histogram with adversary 30, non adversarial : min: -2631.127422905456 max: -2380.727013316453 avg: -2540.3681008574213\n",
            "Copula Based Outlier Detector\n",
            "For Copula with adversary 30, adversarial : min: 988.5504804440675 max: 1191.4658654643035 avg: 1057.2750777069293\n",
            "For Copula with adversary 30, non adversarial : min: 908.4697148665562 max: 1098.8512325298598 avg: 988.7167335338391\n",
            "Time 2023-08-11 15:28:55.105376: Accuracy is 1449/2000 = 0.7245 with 30 attacker after average\n",
            "Time 2023-08-11 15:28:55.117762: Accuracy is 434/2000 = 0.217 with 30 attacker poisonus hyperplane\n",
            "Time 2023-08-11 15:28:55.129711: Accuracy is 1576/2000 = 0.788 with 30 attacker good hyperplane\n",
            "Time 2023-08-11 15:28:55.561619: Accuracy is 1449/2000 = 0.7245 with 30 attacker after clustering\n",
            "Time 2023-08-11 15:29:03.825053: Accuracy is 1449/2000 = 0.7245 with 30 attacker after convergence\n",
            "Time 2023-08-11 15:29:03.873885: Accuracy is 1618/2000 = 0.809 with 30 attacker after krum\n",
            "Time 2023-08-11 15:29:03.885550: Accuracy is 1678/2000 = 0.839 with 30 attacker after multi-krum\n",
            "Time 2023-08-11 15:29:03.927479: Accuracy is 1131/2000 = 0.5655 with 30 attacker after trimmed mean\n",
            "\n",
            "IJCNN1 LABEL_FLIP INDIV 100 50\n",
            "kNN based out detection\n",
            "For kNN with adversary 30, adversarial : min: 0.21444232851225975 max: 2.5294134214095694 avg: 0.3727713130780754\n",
            "For kNN with adversary 30, non adversarial : min: 0.13243676765327672 max: 165.1581813450157 avg: 3.121710337065312\n",
            "Histogram based out detection\n",
            "For Histogram with adversary 30, adversarial : min: -34.98677007533128 max: -23.260453745528796 avg: -31.38313205763664\n",
            "For Histogram with adversary 30, non adversarial : min: -38.35072334659127 max: -14.866441729779797 avg: -28.906718562694117\n",
            "Copula Based Outlier Detector\n",
            "For Copula with adversary 30, adversarial : min: 23.173122591473003 max: 33.331333990554164 avg: 27.513516230009646\n",
            "For Copula with adversary 30, non adversarial : min: 19.29640994916372 max: 48.51440768985435 avg: 30.922262898870844\n",
            "Time 2023-08-11 15:29:05.620662: Accuracy is 82989/91701 = 0.9049955834723722 with 30 attacker after average\n",
            "Time 2023-08-11 15:29:06.015135: Accuracy is 8712/91701 = 0.09500441652762784 with 30 attacker poisonus hyperplane\n",
            "Time 2023-08-11 15:29:06.394760: Accuracy is 82379/91701 = 0.8983435295144001 with 30 attacker good hyperplane\n",
            "Time 2023-08-11 15:29:06.781880: Accuracy is 82989/91701 = 0.9049955834723722 with 30 attacker after clustering\n",
            "Time 2023-08-11 15:29:07.357864: Accuracy is 82989/91701 = 0.9049955834723722 with 30 attacker after convergence\n",
            "Time 2023-08-11 15:29:07.760827: Accuracy is 83121/91701 = 0.9064350443288514 with 30 attacker after krum\n",
            "Time 2023-08-11 15:29:08.145470: Accuracy is 82978/91701 = 0.9048756284009989 with 30 attacker after multi-krum\n",
            "Time 2023-08-11 15:29:08.537187: Accuracy is 82974/91701 = 0.904832008375045 with 30 attacker after trimmed mean\n",
            "\n",
            "IJCNN1 OPTIMAL INDIV 100 50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-0c08df21f94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mclfLocals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCClassifierSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mclfLocals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclfLocals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclfLocals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/secml/ml/classifiers/c_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;31m# TODO: add option to exclude xval or customize it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/secml/ml/c_module.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0m_fit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m  \u001b[0;31m# Same doc for the protected method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/secml/ml/classifiers/sklearn/c_classifier_svm.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;31m# fit binary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_binary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvc_kernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0;31m# remove unused support vectors from kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/secml/ml/classifiers/sklearn/c_classifier_svm.py\u001b[0m in \u001b[0;36m_fit_binary\u001b[0;34m(self, x, y, svc_kernel)\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtondarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m             \u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    197\u001b[0m             )\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         sample_weight = np.asarray(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_validate_targets\u001b[0;34m(self, y)\u001b[0m\n\u001b[1;32m    718\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    721\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one; got %d class\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
          ]
        }
      ],
      "source": [
        "#@title Default title text\n",
        "dataset_type = 'IJCNN1' # 'MNIST' # 'CIFAR10' # 'FASHION_MNIST' #\n",
        "ATTACK_TYPE = 'OPTIMAL' # 'OUR_ATTACK_GD' # 'OUR_ATTACK' #  'FANG_KRUM' # 'AGR_KRUM' # 'LABEL_FLIP' # 'RANDOM' # 'LIE' #'OUR_ATTACK_BND_KRUM' # 'GRADIENT' #\n",
        "MODE = 'INDIV' # 'COLLABORAT' #   #\n",
        "num_local_machine = 100\n",
        "iid_deg=50\n",
        "\n",
        "for dataset_type, ATTACK_TYPE, iid_deg in itertools.product(['CIFAR10', 'FASHION_MNIST', 'IJCNN1'], ['LABEL_FLIP', 'OPTIMAL'], range(50, 51, 10)) :\n",
        "# for iid_deg in range(50, 51, 10):\n",
        "    # print(dataset_type, ATTACK_TYPE, MODE, num_local_machine)\n",
        "    print()\n",
        "    print(dataset_type, ATTACK_TYPE, MODE, num_local_machine, iid_deg)\n",
        "    dataLoad(iid_deg)\n",
        "\n",
        "\n",
        "    # for advNumber in [0, 5, 10, 15, 20, 25, 30, 35, 40, 45]: # advNumber means how many attackers\n",
        "    for advNumber in [30]: # advNumber means how many attackers\n",
        "\n",
        "        hSets = []\n",
        "        for local_machine in range(num_local_machine):\n",
        "            X_local, y_local= load_local_data(advNumber, local_machine)\n",
        "\n",
        "            # print(local_machine, y_local)\n",
        "\n",
        "            clfLocals = CClassifierSVM(C=1)\n",
        "            clfLocals.fit(X_local, y_local)\n",
        "\n",
        "            w, b = clfLocals.w.get_data()[0], clfLocals.b.get_data()[0]\n",
        "            m = np.sqrt(w.dot(w))\n",
        "            w = w / m\n",
        "            b /= m\n",
        "\n",
        "            w, b = model_change(advNumber, local_machine, w, b)\n",
        "            hSets.append(np.append(w,b))\n",
        "\n",
        "\n",
        "        outler_input = deepcopy(hSets)\n",
        "        if advNumber == 30:\n",
        "            outlier_detection(deepcopy(hSets), advNumber, num_local_machine)\n",
        "        # Average\n",
        "        w = np.mean(hSets, axis=0)\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after average')\n",
        "\n",
        "            # First\n",
        "        w = hSets[0]\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker poisonus hyperplane')\n",
        "\n",
        "\n",
        "            # Average\n",
        "        w = hSets[70]\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker good hyperplane')\n",
        "\n",
        "\n",
        "\n",
        "        # Clustering\n",
        "        kmeans = KMeans(n_clusters=1, random_state=0).fit(hSets)\n",
        "        w = kmeans.cluster_centers_[0]\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1): cnt += 1\n",
        "            # print(det, testX[i], testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after clustering')\n",
        "\n",
        "\n",
        "        # Convergence\n",
        "        isUpdated = True\n",
        "        iter = 10000\n",
        "        while isUpdated and iter > 0:\n",
        "            iter -= 1\n",
        "            isUpdated = False\n",
        "            kmeans = KMeans(n_clusters=1, random_state=0).fit(hSets)\n",
        "            w = kmeans.cluster_centers_[0]\n",
        "            for i in range(num_local_machine):\n",
        "                if not np.allclose(w, hSets[i]):\n",
        "                    hSets[i] = np.mean( np.array([ hSets[i], w ]), axis=0 )\n",
        "                    isUpdated = True\n",
        "\n",
        "        kmeans = KMeans(n_clusters=1, random_state=0).fit(hSets)\n",
        "        w = kmeans.cluster_centers_[0]\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1): cnt += 1\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after convergence')\n",
        "\n",
        "            # Krum\n",
        "        hSets = deepcopy(outler_input)\n",
        "\n",
        "        krum_scores = []\n",
        "        byzantine_client_num = num_local_machine // 5\n",
        "        for i in range(0, num_local_machine):\n",
        "            dists = []\n",
        "            for j in range(0, num_local_machine):\n",
        "                if i != j:\n",
        "                    temp_vector = np.subtract(hSets[i], hSets[j])\n",
        "                    distance = np.dot(temp_vector,temp_vector)\n",
        "                    dists.append(distance)\n",
        "            #   print(i, \"all_socre\", dists)\n",
        "            dists.sort()  # ascending\n",
        "            score = dists[0 : num_local_machine - byzantine_client_num - 2]\n",
        "            #   print(i, \"low_socre\", score)\n",
        "            krum_scores.append(sum(score))\n",
        "            #   print(i, sum(score))\n",
        "        score_index = np.argsort(krum_scores)  # indices; ascending\n",
        "        score_index = score_index[0 : num_local_machine - byzantine_client_num - 2]\n",
        "        #   print(krum_scores)\n",
        "        #   print(score_index)\n",
        "        hSets = [outler_input[i] for i in score_index]\n",
        "\n",
        "        w = hSets[0]\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after krum')\n",
        "\n",
        "        w = np.mean(hSets, axis=0)\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after multi-krum')\n",
        "\n",
        "\n",
        "\n",
        "        # Trimmed Mean\n",
        "        hSets = deepcopy(outler_input)\n",
        "\n",
        "        trimmed_num = int(len(hSets)*0.2)\n",
        "        temp_hSets = np.zeros((len(hSets) - 2*trimmed_num, len(hSets[0])))\n",
        "        #   print(temp_hSets)\n",
        "        for j in range(len(hSets[0])):\n",
        "            temp_hSet = []\n",
        "            for i in range(len(hSets)):\n",
        "                temp_hSet.append(hSets[i][j])\n",
        "            temp_hSet.sort()\n",
        "            #   print(temp_hSet)\n",
        "            for i in range(trimmed_num, len(temp_hSet) - trimmed_num):\n",
        "                #   print(i, j, i-trimmed_num)\n",
        "                temp_hSets[i-trimmed_num][j] = temp_hSet[i]\n",
        "        hSets = temp_hSets\n",
        "\n",
        "        w = np.mean(hSets, axis=0)\n",
        "\n",
        "        cnt = 0\n",
        "        for i in range(len(testX)):\n",
        "            det = np.dot(np.append(testX[i], 1), w)\n",
        "            if (det < 0 and testy[i] == 0) or (det > 0 and testy[i] == 1):\n",
        "                cnt += 1\n",
        "            # print(i, det, testy[i])\n",
        "        print(f'Time {datetime.now()}: Accuracy is {cnt}/{len(testX)} = {cnt/len(testX)} with {advNumber} attacker after trimmed mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE_0Sn3i9nEb"
      },
      "outputs": [],
      "source": [
        "gd_hSets = deepcopy(outler_input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bnd_hSets = deepcopy(outler_input)"
      ],
      "metadata": {
        "id": "MTKp8oXBPVDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_vector = np.subtract([1,2,3], [5,6,3])\n",
        "distance = np.dot(temp_vector,temp_vector)\n",
        "print(distance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssuUA7kwWdP",
        "outputId": "605998c1-175f-4b59-a1a2-baaa6ce2e39a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df = pd.read_csv('/content/sample_data/fashion-mnist_train.csv')\n",
        "test_df = pd.read_csv('/content/sample_data/fashion-mnist_test.csv')\n",
        "print('The shape of training dataset : ', train_df.shape)\n",
        "print('The shape of testing dataset : ', test_df.shape)\n",
        "\n",
        "train = np.array(train_df, dtype = 'float32')\n",
        "test = np.array(test_df, dtype = 'float32')\n",
        "\n",
        "\n",
        "x_train = train[:,1:]/255\n",
        "\n",
        "y_train = train[:,0]\n",
        "\n",
        "x_test= test[:,1:]/255\n",
        "\n",
        "y_test=test[:,0]\n",
        "\n",
        "\n",
        "X_train, X_validate,y_train, y_validate = train_test_split(x_train, y_train, test_size = 0.2, random_state = 5000)\n",
        "print('The size of training data after model selection : ', X_train.shape, y_train.shape)\n",
        "print('The size of Validation data after model selection : ', X_validate.shape, y_validate.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnlgKfsWrytI",
        "outputId": "528840f9-b0cf-46ec-89c2-cace493335c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training dataset :  (60000, 785)\n",
            "The shape of testing dataset :  (10000, 785)\n",
            "The size of training data after model selection :  (48000, 784) (48000,)\n",
            "The size of Validation data after model selection :  (12000, 784) (12000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import bz2\n",
        "from sklearn.datasets import load_svmlight_file\n",
        "import pandas as pd\n",
        "\n",
        "# Open the compressed file\n",
        "# Load the LibSVM format data\n",
        "X, y = load_svmlight_file('/content/sample_data/ijcnn1.t.bz2')\n",
        "print(len(X.toarray()[0]), len(y))\n",
        "print(np.unique(y, return_counts=True))\n",
        "\n",
        "# Convert to a dense array and then to a DataFrame\n",
        "df = pd.DataFrame(X.toarray())\n",
        "\n",
        "# Adding target variable to DataFrame\n",
        "df['target'] = y\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lspgfJJeJ2t",
        "outputId": "ea333fb4-c82d-49f5-9da7-936f7dc37042"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22 91701\n",
            "(array([-1.,  1.]), array([82989,  8712]))\n",
            "     0    1    2    3    4    5    6    7    8    9  ...        13        14  \\\n",
            "0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.000292 -0.020372   \n",
            "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  ... -0.020372  0.007305   \n",
            "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.007305  0.002519   \n",
            "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.002519  0.018198   \n",
            "4  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.018198 -0.024526   \n",
            "\n",
            "         15        16        17        18        19        20        21  \\\n",
            "0  0.007305  0.002519  0.018198 -0.024526  0.012458 -0.016884  0.006842   \n",
            "1  0.002519  0.018198 -0.024526  0.012458 -0.016884  0.006842  0.005018   \n",
            "2  0.018198 -0.024526  0.012458 -0.016884  0.006842  0.005018  0.016210   \n",
            "3 -0.024526  0.012458 -0.016884  0.006842  0.005018  0.016210 -0.027162   \n",
            "4  0.012458 -0.016884  0.006842  0.005018  0.016210 -0.027162  0.026788   \n",
            "\n",
            "   target  \n",
            "0    -1.0  \n",
            "1    -1.0  \n",
            "2    -1.0  \n",
            "3    -1.0  \n",
            "4    -1.0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "!rm /content/sample_data/fashion-mnist_train.csv\n",
        "!rm /content/sample_data/fashion-mnist_test.csv\n",
        "!wget https://dax-cdn.cdn.appdomain.cloud/dax-fashion-mnist/1.0.2/fashion-mnist.tar.gz -O /content/sample_data/fashion-mnist.tar.gz\n",
        "!tar -xvzf /content/sample_data/fashion-mnist.tar.gz -C /content/sample_data/\n",
        "!ls -lS /content/sample_data/\n",
        "for dirname, _, filenames in os.walk('/content'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM2Ivlrdsqja",
        "outputId": "0391b7dc-f7a3-4a2d-c985-90b488da8a1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "rm: cannot remove '/content/sample_data/fashion-mnist_train.csv': No such file or directory\n",
            "rm: cannot remove '/content/sample_data/fashion-mnist_test.csv': No such file or directory\n",
            "--2023-07-20 09:21:43--  https://dax-cdn.cdn.appdomain.cloud/dax-fashion-mnist/1.0.2/fashion-mnist.tar.gz\n",
            "Resolving dax-cdn.cdn.appdomain.cloud (dax-cdn.cdn.appdomain.cloud)... 23.54.209.135, 2600:1408:20:599::d2d, 2600:1408:20:587::d2d\n",
            "Connecting to dax-cdn.cdn.appdomain.cloud (dax-cdn.cdn.appdomain.cloud)|23.54.209.135|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 38564215 (37M) [application/x-tar]\n",
            "Saving to: /content/sample_data/fashion-mnist.tar.gz\n",
            "\n",
            "/content/sample_dat 100%[===================>]  36.78M  72.4MB/s    in 0.5s    \n",
            "\n",
            "2023-07-20 09:21:44 (72.4 MB/s) - /content/sample_data/fashion-mnist.tar.gz saved [38564215/38564215]\n",
            "\n",
            "fashion-mnist_test.csv\n",
            "fashion-mnist_train.csv\n",
            "LICENSE.txt\n",
            "total 248668\n",
            "-rw-r--r-- 1 root root 133047193 Dec  6  2017 fashion-mnist_train.csv\n",
            "-rw-r--r-- 1 root root  38564215 Mar 20  2020 fashion-mnist.tar.gz\n",
            "-rw-r--r-- 1 root root  36523880 Feb 13 14:35 mnist_train_small.csv\n",
            "-rw-r--r-- 1 root root  22176691 Dec  6  2017 fashion-mnist_test.csv\n",
            "-rw-r--r-- 1 root root  18289443 Feb 13 14:35 mnist_test.csv\n",
            "-rw-r--r-- 1 root root   2597597 Aug  6  2007 ijcnn1.t.bz2\n",
            "-rw-r--r-- 1 root root   1706430 Feb 13 14:35 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root    964465 Jun  8  2005 ijcnn1.tr.bz2\n",
            "-rw-r--r-- 1 root root    429604 Jun  8  2005 ijcnn1.val.bz2\n",
            "-rw-r--r-- 1 root root    301141 Feb 13 14:35 california_housing_test.csv\n",
            "-rwxr-xr-x 1 root root      1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root      1112 Aug 22  2019 LICENSE.txt\n",
            "-rwxr-xr-x 1 root root       930 Jan  1  2000 README.md\n",
            "/content/.config/gce\n",
            "/content/.config/.last_opt_in_prompt.yaml\n",
            "/content/.config/.last_survey_prompt.yaml\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/active_config\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/logs/2023.02.13/14.34.24.375813.log\n",
            "/content/.config/logs/2023.02.13/14.34.59.388963.log\n",
            "/content/.config/logs/2023.02.13/14.34.58.574917.log\n",
            "/content/.config/logs/2023.02.13/14.33.33.557635.log\n",
            "/content/.config/logs/2023.02.13/14.34.32.398664.log\n",
            "/content/.config/logs/2023.02.13/14.33.58.917530.log\n",
            "/content/.config/configurations/config_default\n",
            "/content/sample_data/anscombe.json\n",
            "/content/sample_data/README.md\n",
            "/content/sample_data/fashion-mnist.tar.gz\n",
            "/content/sample_data/ijcnn1.t.bz2\n",
            "/content/sample_data/LICENSE.txt\n",
            "/content/sample_data/ijcnn1.tr.bz2\n",
            "/content/sample_data/fashion-mnist_train.csv\n",
            "/content/sample_data/fashion-mnist_test.csv\n",
            "/content/sample_data/ijcnn1.val.bz2\n",
            "/content/sample_data/mnist_train_small.csv\n",
            "/content/sample_data/california_housing_test.csv\n",
            "/content/sample_data/mnist_test.csv\n",
            "/content/sample_data/california_housing_train.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print('Loading ijcnn1 dataset')\n",
        "print(os.getcwd())\n",
        "!rm /content/sample_data/ijcnn1.t.bz2\n",
        "!rm /content/sample_data/ijcnn1.tr.bz2\n",
        "!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.t.bz2 -O /content/sample_data/ijcnn1.t.bz2\n",
        "!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.tr.bz2 -O /content/sample_data/ijcnn1.tr.bz2\n",
        "!wget https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.val.bz2 -O /content/sample_data/ijcnn1.val.bz2\n",
        "!ls -lS /content/sample_data/\n",
        "for dirname, _, filenames in os.walk('/content'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "GQLiqmXfTsrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a6302cd-72ac-4b4c-96c7-3af7be494251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ijcnn1 dataset\n",
            "/content\n",
            "rm: cannot remove '/content/sample_data/ijcnn1.t.bz2': No such file or directory\n",
            "rm: cannot remove '/content/sample_data/ijcnn1.tr.bz2': No such file or directory\n",
            "--2023-07-20 09:21:19--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.t.bz2\n",
            "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n",
            "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2597597 (2.5M) [application/x-bzip2]\n",
            "Saving to: /content/sample_data/ijcnn1.t.bz2\n",
            "\n",
            "/content/sample_dat 100%[===================>]   2.48M  1.84MB/s    in 1.3s    \n",
            "\n",
            "2023-07-20 09:21:22 (1.84 MB/s) - /content/sample_data/ijcnn1.t.bz2 saved [2597597/2597597]\n",
            "\n",
            "--2023-07-20 09:21:22--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.tr.bz2\n",
            "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n",
            "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 964465 (942K) [application/x-bzip2]\n",
            "Saving to: /content/sample_data/ijcnn1.tr.bz2\n",
            "\n",
            "/content/sample_dat 100%[===================>] 941.86K   816KB/s    in 1.2s    \n",
            "\n",
            "2023-07-20 09:21:24 (816 KB/s) - /content/sample_data/ijcnn1.tr.bz2 saved [964465/964465]\n",
            "\n",
            "--2023-07-20 09:21:24--  https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/ijcnn1.val.bz2\n",
            "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\n",
            "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 429604 (420K) [application/x-bzip2]\n",
            "Saving to: /content/sample_data/ijcnn1.val.bz2\n",
            "\n",
            "/content/sample_dat 100%[===================>] 419.54K   441KB/s    in 1.0s    \n",
            "\n",
            "2023-07-20 09:21:25 (441 KB/s) - /content/sample_data/ijcnn1.val.bz2 saved [429604/429604]\n",
            "\n",
            "total 59408\n",
            "-rw-r--r-- 1 root root 36523880 Feb 13 14:35 mnist_train_small.csv\n",
            "-rw-r--r-- 1 root root 18289443 Feb 13 14:35 mnist_test.csv\n",
            "-rw-r--r-- 1 root root  2597597 Aug  6  2007 ijcnn1.t.bz2\n",
            "-rw-r--r-- 1 root root  1706430 Feb 13 14:35 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root   964465 Jun  8  2005 ijcnn1.tr.bz2\n",
            "-rw-r--r-- 1 root root   429604 Jun  8  2005 ijcnn1.val.bz2\n",
            "-rw-r--r-- 1 root root   301141 Feb 13 14:35 california_housing_test.csv\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n",
            "/content/.config/gce\n",
            "/content/.config/.last_opt_in_prompt.yaml\n",
            "/content/.config/.last_survey_prompt.yaml\n",
            "/content/.config/config_sentinel\n",
            "/content/.config/active_config\n",
            "/content/.config/.last_update_check.json\n",
            "/content/.config/logs/2023.02.13/14.34.24.375813.log\n",
            "/content/.config/logs/2023.02.13/14.34.59.388963.log\n",
            "/content/.config/logs/2023.02.13/14.34.58.574917.log\n",
            "/content/.config/logs/2023.02.13/14.33.33.557635.log\n",
            "/content/.config/logs/2023.02.13/14.34.32.398664.log\n",
            "/content/.config/logs/2023.02.13/14.33.58.917530.log\n",
            "/content/.config/configurations/config_default\n",
            "/content/sample_data/anscombe.json\n",
            "/content/sample_data/README.md\n",
            "/content/sample_data/ijcnn1.t.bz2\n",
            "/content/sample_data/ijcnn1.tr.bz2\n",
            "/content/sample_data/ijcnn1.val.bz2\n",
            "/content/sample_data/mnist_train_small.csv\n",
            "/content/sample_data/california_housing_test.csv\n",
            "/content/sample_data/mnist_test.csv\n",
            "/content/sample_data/california_housing_train.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFOjO0JmZy+dz68P1XKKWD",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}